# Opci√≥n A - Quick Wins Implementation Plan

**Timeline**: Semana 1  
**Objetivo**: Desbloquear problemas inmediatos y mejorar estabilidad del sistema

---

## üéØ Overview

Tres mejoras cr√≠ticas de alto impacto:
1. **Scraping NameMC con Fallback Autom√°tico** - Resolver rate limiting de 429 errors
2. **Scoring Probabil√≠stico para Semi-Premium** - Mejorar precisi√≥n de detecci√≥n
3. **Dashboard de M√©tricas de Scraping** - Visibilidad del sistema

---

## Task 1: Scraping NameMC - Sistema de Fallback Autom√°tico

### Problema Actual
- Scraper simple con `requests` falla con 429 (rate limiting)
- Scraper Selenium existe pero no hay fallback autom√°tico
- No hay rotaci√≥n inteligente de estrategias

### Soluci√≥n Propuesta

```python
class AdaptiveScraper:
    def scrape_page(self, url):
        try:
            # Strategy 1: Fast requests-based
            return self.fast_scrape(url)
        except RateLimitError:
            # Strategy 2: Rotate proxy + retry
            self.rotate_proxy()
            return self.fast_scrape(url)
        except ScraperError:
            # Strategy 3: Selenium fallback
            return self.selenium_scrape(url)
```

### Implementaci√≥n

#### 1.1 Crear `core/adaptive_scraper.py`
- [ ] Clase `AdaptiveScraper` con estrategias m√∫ltiples
- [ ] M√©todo `fast_scrape()` usando requests + cloudscraper
- [ ] M√©todo `selenium_scrape()` con headless browser
- [ ] M√©todo `rotate_proxy()` integrando `proxy_manager.py`
- [ ] Sistema de backoff exponencial

#### 1.2 Excepciones personalizadas
```python
class RateLimitError(Exception): pass
class ScraperError(Exception): pass
```

#### 1.3 Integrar con scrapers existentes
- [ ] Refactorizar `scrape_namemc_600.py`
- [ ] Refactorizar `scrape_namemc_enterprise.py`
- [ ] Usar `AdaptiveScraper` en lugar de l√≥gica directa

#### 1.4 Testing
- [ ] Crear `tests/test_adaptive_scraper.py`
- [ ] Test de fallback autom√°tico
- [ ] Test de rotaci√≥n de proxy
- [ ] Test de Selenium fallback

### Archivos a Modificar/Crear
- **NUEVO**: `core/adaptive_scraper.py`
- **MODIFICAR**: `scrape_namemc_600.py`
- **MODIFICAR**: `scrape_namemc_enterprise.py`
- **NUEVO**: `tests/test_adaptive_scraper.py`

### Tiempo Estimado
2-3 d√≠as

---

## Task 2: Scoring Probabil√≠stico para Semi-Premium

### Problema Actual
- Detecci√≥n es binaria (s√≠/no) basada en heur√≠sticas
- No hay confianza asociada a la clasificaci√≥n
- Dif√≠cil auditar por qu√© un servidor fue clasificado de cierta forma

### Soluci√≥n Propuesta

Sistema de scoring donde cada se√±al contribuye puntos:

```python
score = 0.0
evidence = []

# Se√±ales positivas (incrementan probabilidad de semi-premium)
if has_auth_plugin: 
    score += 0.3
    evidence.append("AUTH_PLUGIN_DETECTED")
    
if is_known_network: 
    score += 0.4
    evidence.append("KNOWN_SEMI_PREMIUM_NETWORK")
    
if large_player_count and hybrid_keywords: 
    score += 0.2
    evidence.append("LARGE_HYBRID_SERVER")

# Se√±ales negativas (reducen probabilidad)
if premium_protocol: 
    score -= 0.5
    evidence.append("PREMIUM_PROTOCOL")

# Clasificaci√≥n final
if score >= 0.8: return PREMIUM
elif score >= 0.4: return SEMI_PREMIUM
else: return NON_PREMIUM
```

### Implementaci√≥n

#### 2.1 Modificar `core/enterprise/detector.py`

**A√±adir clase `DetectionEvidence`**:
```python
@dataclass
class DetectionEvidence:
    signal: str
    weight: float
    description: str
    timestamp: datetime
```

**A√±adir m√©todo `_calculate_score()`**:
- [ ] Evaluar todas las se√±ales
- [ ] Acumular score con pesos configurables
- [ ] Retornar score + lista de evidencias

#### 2.2 Configuraci√≥n de pesos
- [ ] Crear `config/detection_weights.yaml`
- [ ] Definir pesos para cada se√±al
- [ ] Permitir ajuste manual

#### 2.3 Almacenar evidencias
- [ ] Modificar `detect()` para retornar evidencias
- [ ] Guardar en metadata del servidor
- [ ] Formato: `{"score": 0.7, "evidence": [...], "classification": "SEMI_PREMIUM"}`

#### 2.4 Testing
- [ ] Tests para scoring con diferentes combinaciones
- [ ] Test de umbrales
- [ ] Test de evidencias guardadas

### Archivos a Modificar/Crear
- **MODIFICAR**: `core/enterprise/detector.py`
- **NUEVO**: `config/detection_weights.yaml`
- **NUEVO**: `tests/test_detection_scoring.py`

### Tiempo Estimado
2-3 d√≠as

---

## Task 3: Dashboard de M√©tricas de Scraping

### Problema Actual
- No hay visibilidad de qu√© est√° pasando con los scrapers
- Dif√≠cil saber si hay problemas de rate limiting
- No se trackean servidores nuevos por d√≠a

### Soluci√≥n Propuesta

Dashboard con m√©tricas en tiempo real:
- Requests por minuto
- Tasa de √©xito/error
- Servidores nuevos descubiertos hoy
- Errores por tipo (429, timeout, etc.)
- √öltimo scrape exitoso

### Implementaci√≥n

#### 3.1 Tabla de m√©tricas en DB

```sql
CREATE TABLE scrape_metrics (
    id INTEGER PRIMARY KEY,
    timestamp DATETIME,
    requests_count INTEGER,
    success_count INTEGER,
    error_count INTEGER,
    error_type VARCHAR(50),
    new_servers_count INTEGER,
    duration_seconds FLOAT
);
```

#### 3.2 Logger de m√©tricas
- [ ] Crear `core/scrape_metrics.py`
- [ ] M√©todo `log_scrape_attempt(success, error_type, duration)`
- [ ] M√©todo `get_metrics(timeframe='24h')`

#### 3.3 API Endpoint
- [ ] A√±adir endpoint `/api/scraping/metrics`
- [ ] Retornar m√©tricas agregadas
- [ ] Filtros por tiempo (1h, 24h, 7d)

#### 3.4 Dashboard UI
- [ ] Crear `web/static/scraping_metrics.html`
- [ ] Gr√°ficos con Chart.js:
  - Requests/min (l√≠nea)
  - Tasa de √©xito (gauge)
  - Nuevos servidores (barra)
  - Errores por tipo (pie)

#### 3.5 Integrar con scrapers
- [ ] Modificar `AdaptiveScraper` para loggear m√©tricas
- [ ] Modificar scrapers existentes

### Archivos a Modificar/Crear
- **NUEVO**: `core/scrape_metrics.py`
- **NUEVO**: `scripts/migrations/002_scrape_metrics.sql`
- **MODIFICAR**: `core/api.py` (nuevo endpoint)
- **NUEVO**: `web/static/scraping_metrics.html`
- **NUEVO**: `web/static/scraping_metrics.js`
- **MODIFICAR**: `core/adaptive_scraper.py`

### Tiempo Estimado
3-4 d√≠as

---

## üìä Resumen de Entregables

Al completar Opci√≥n A tendr√°s:

‚úÖ **Sistema de scraping resiliente** que nunca se bloquea  
‚úÖ **Detecci√≥n semi-premium auditable** con scoring y evidencias  
‚úÖ **Visibilidad completa** del sistema de scraping v√≠a dashboard

---

## üîÑ Orden de Ejecuci√≥n Sugerido

1. **Task 1** primero (desbloquea scraping inmediatamente)
2. **Task 3** segundo (te da visibilidad mientras trabajas en Task 2)
3. **Task 2** tercero (ya con datos fluyendo bien)

O alternativamente:

1. **Task 2** primero (si detecci√≥n es m√°s urgente)
2. **Task 1** segundo
3. **Task 3** tercero

---

## üö¶ Criterios de Completitud

### Task 1 - Scraping
- [ ] Scraper puede completar 600 p√°ginas sin fallar
- [ ] Fallback a Selenium funciona autom√°ticamente
- [ ] Tests pasan

### Task 2 - Scoring
- [ ] Cada servidor tiene score + evidencias
- [ ] Scores son consistentes y calibrados
- [ ] Tests pasan

### Task 3 - M√©tricas
- [ ] Dashboard muestra m√©tricas en tiempo real
- [ ] API endpoint funciona correctamente
- [ ] Gr√°ficos se actualizan autom√°ticamente

---

## üéØ Pr√≥ximo Paso

**¬øQu√© task quer√©s que empiece primero?**
- Task 1: Scraping con fallback
- Task 2: Scoring probabil√≠stico
- Task 3: Dashboard de m√©tricas
